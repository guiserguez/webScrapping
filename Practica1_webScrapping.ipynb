{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica1_webScrapping_entrega.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "LFj_7SBtxGko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**@author Güise Rodríguez**\n",
        "\n",
        "**Execution date: 06/04/2019 21:30 **"
      ]
    },
    {
      "metadata": {
        "id": "_hLmGmf_i_pX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Instalo las librerías necesarias"
      ]
    },
    {
      "metadata": {
        "id": "Za2TOrCUvCWL",
        "colab_type": "code",
        "outputId": "30cd2bda-9853-4e94-c2dd-6d5896b3458b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install requests\n",
        "!pip3 install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J8I-ZQ2KkAMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importo las librerías necesarias"
      ]
    },
    {
      "metadata": {
        "id": "OMdBbWrfkAaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests, sys, re, csv\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xysVUTGkB3d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# It's show time!"
      ]
    },
    {
      "metadata": {
        "id": "7N7nfEFIcWPq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Funciones auxiliares"
      ]
    },
    {
      "metadata": {
        "id": "w1BsJ7a1f0Aw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_author(extract):\n",
        "  authors = []\n",
        "  for autora in extract.find_all(\"a\"):\n",
        "    authors.append(re.sub(' +',' ',autora['title']))\n",
        "  if authors:\n",
        "    return \",\".join(map(str,authors))\n",
        "  #Si es un colectivo, el nombre aparecería con dicho formato\n",
        "  return re.sub(' +',' ',re.sub('-','',re.sub('\\n','',datos.contents[0]))).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyGc5Rt0RshI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(extract):\n",
        "    extra = extract.find(\"span\",{\"class\": \"location\"})\n",
        "    if 'lst-item-opinion' in extract.get(\"class\"):\n",
        "      type = \"opinion\"\n",
        "      if extra:\n",
        "        authorInfo = extra.getText()\n",
        "        location = \"\"\n",
        "    else:\n",
        "      type = \"news\"\n",
        "      if extra:\n",
        "        authorInfo = \"\"\n",
        "        location = extra.getText()\n",
        "    if extra is None:\n",
        "      authorInfo = \"\"\n",
        "      location = \"\"\n",
        "    return type, authorInfo, location"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3pZtd7zcZU7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Código principal"
      ]
    },
    {
      "metadata": {
        "id": "_nY9eNPwE26b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base = \"https://www.eldiario.es/focos/\"\n",
        "focos = ['mejores_ciudades','vida_digital','creacion_cultural','medio_ambiente','maltrato_animal']\n",
        "depth = [12,23,41,36,10]\n",
        "header = ['headline','type','date','section','author','authorInfo','location','url']\n",
        "csvData = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJAhflzlE23Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, foco in enumerate(focos):\n",
        "  for nPage in np.arange(depth[i])+1:\n",
        "    target = base + foco + \"/?page=\" + str(nPage) \n",
        "    request = requests.get(target)\n",
        "    if request.status_code != 200:\n",
        "      sys.exit(\"Error Code: \" + str(request.status_code))\n",
        "    soup = BeautifulSoup(request.content)\n",
        "    body = soup.find(\"div\",{\"class\": \"pg-body\"})\n",
        "    for noticia in body.find_all(\"li\",{\"class\": \"lst-item\"}):\n",
        "      type, authorInfo, location = get_data(noticia)\n",
        "      datos = noticia.find(\"span\",{\"class\": \"byline\"})\n",
        "      headline = re.sub(\"\\\\\\\\'\",\"\\'\",noticia.find(\"a\")['title']) #Sustituyo \"\\\\'\" por una comilla simple\n",
        "      date = datos.find(\"span\",{\"class\": \"date\"}).getText()\n",
        "      author = get_author(datos)\n",
        "      url = \"eldiario.es\" + noticia.find(\"a\")['href']\n",
        "      csvData.append([headline,type,date,foco,author,authorInfo,location,url])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vq45YVIs03h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dfObj = pd.DataFrame(csvData, columns= header)\n",
        "dfObj.to_csv(\"eldiario_news.csv\",sep=\";\",index=False,quoting=csv.QUOTE_MINIMAL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}